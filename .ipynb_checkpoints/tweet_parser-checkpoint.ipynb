{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Bitcoin\n",
    "@CoinMarketCap\n",
    "@elonmusk\n",
    "@CoinDesk\n",
    "@CoinDeskMarkets\n",
    "@CoinDeskData\n",
    "@coinbase\n",
    "@CoinbaseSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prs_twtr(path):\n",
    "    with open(path, 'r') as f:\n",
    "        contents = f.read()\n",
    "        page_soup = BeautifulSoup(contents, 'html.parser')\n",
    "\n",
    "    # finds each product from the store page\n",
    "    containers = page_soup.findAll(\"article\")\n",
    "\n",
    "    lista_tweet = []\n",
    "    lista_data = []\n",
    "    lista_reply = []\n",
    "    lista_commenti = []\n",
    "    lista_retweet = []\n",
    "    lista_like = []\n",
    "\n",
    "    for cnt in containers:\n",
    "        # tweet\n",
    "        try:\n",
    "            tweet = cnt.findAll(\"div\", {\"class\": \"css-901oao r-jwli3a r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\"}) \n",
    "            \n",
    "            try:\n",
    "                ls = tweet[0].findAll(\"span\")\n",
    "            except LookupError:\n",
    "                ls = \"****\"\n",
    "\n",
    "            tmp1 = []\n",
    "            \n",
    "            for i in range(len(ls)):\n",
    "                try:\n",
    "                    tmp1.append(ls[i].text)\n",
    "                except AttributeError:\n",
    "                    tmp1.append(ls)\n",
    "\n",
    "            string1 = \" \".join(tmp1)\n",
    "\n",
    "            lista_tweet.append(string1)\n",
    "\n",
    "        except LookupError:\n",
    "            lista_tweet.append(\"****\")\n",
    "\n",
    "        # data del tweet\n",
    "        try:\n",
    "            data = cnt.findAll(\"time\")\n",
    "            dict = data[0].attrs\n",
    "            ls1 = str(dict.values())\n",
    "            lista_data.append(ls1[14:-8])\n",
    "\n",
    "        except LookupError:\n",
    "            lista_data.append(\"****\")\n",
    "\n",
    "        # reply\n",
    "        try:\n",
    "            reply = cnt.findAll(\"div\", {\n",
    "                                \"class\": \"css-901oao r-111h2gw r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-qvutc0\"})\n",
    "            ls2 = reply[0].findAll(\"a\")\n",
    "            tmp = []\n",
    "            for x in range(len(ls2)):\n",
    "                tmp.append(ls2[x]['href'])\n",
    "                \n",
    "            string = \" \".join(tmp)\n",
    "            lista_reply.append(string)\n",
    "\n",
    "        except LookupError:\n",
    "            lista_reply.append(\" \")\n",
    "\n",
    "        # num commenti\n",
    "        try:\n",
    "            commenti = cnt.findAll(\n",
    "                \"div\", {\"class\": \"css-1dbjc4n r-18u37iz r-1h0z5md\"})\n",
    "            ls3 = commenti[0].span.text\n",
    "            lista_commenti.append(ls3)\n",
    "            \n",
    "        except LookupError:\n",
    "            lista_commenti.append('****')\n",
    "\n",
    "        # num retweet\n",
    "        try:\n",
    "            ls4 = commenti[1].span.text\n",
    "\n",
    "            lista_retweet.append(ls4)\n",
    "        except LookupError:\n",
    "            lista_retweet.append('****')\n",
    "\n",
    "        # num like\n",
    "        try:\n",
    "            ls5 = commenti[2].span.text\n",
    "\n",
    "            lista_like.append(ls5)\n",
    "        except LookupError:\n",
    "            lista_like.append('****')\n",
    "\n",
    "    cols = [\"tweet\", \"data\", \"reply\", \"commenti\", \"retweet\", \"like\"]\n",
    "    df = pd.DataFrame(list(zip(lista_tweet, lista_data, lista_reply, lista_commenti, lista_retweet, lista_like)),\n",
    "                      columns=cols)\n",
    "\n",
    "    return(clean_parsed(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_fishes = ['Bitcoin','CoinMarketCap','elonmusk','CoinDesk','CoinDeskMarkets','CoinDeskData','coinbase','CoinbaseSuppor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parsed(df):\n",
    "    df['data'] = pd.to_datetime(df['data'].str.replace('T',' '))\n",
    "    df.set_index('data', drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.3 s, sys: 1.16 s, total: 43.4 s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {'profile.default_content_setting_values': { 'images': 2 }}\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "cols = [\"tweet\",\"data\",\"reply\",\"commenti\",\"retweet\",\"like\" ]\n",
    "final = pd.DataFrame([],columns=cols)\n",
    "chrome_path = \"/Users/matteoprandi/Desktop/chromedriver\"\n",
    "base_path = \"/Users/matteoprandi/Desktop/tweet_test/\"\n",
    "source_path = base_path + \"page_source.html\"\n",
    "\n",
    "ls_account=[\"CoinMarketCap\"]\n",
    "dt_since=\"2020-01-01\"\n",
    "dt_until=\"2021-01-01\"\n",
    "\n",
    "for fish in big_fishes:\n",
    "    url = \"https://twitter.com/search?q=From%3A\" + fish + \"%20since%3A\"+ dt_since +\"%20until%3A\"+ dt_until + \"&src=typed_query&f=live\"\n",
    "\n",
    "    driver = webdriver.Chrome(options=options, executable_path=chrome_path)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    dummy = 0\n",
    "\n",
    "    while True:\n",
    "        with open(source_path, \"w\") as f:\n",
    "            f.write(driver.page_source)\n",
    "\n",
    "        df = prs_twtr(source_path)\n",
    "        final = final.append(df)\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        driver.execute_script(\"window.scrollTo(0, {})\".format(last_height + 500))\n",
    "        time.sleep(1)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                \n",
    "        if (final.shape[0] - dummy) >= 250:\n",
    "            driver.close()\n",
    "            dt_until = str(final.index[-10].date())\n",
    "            url = \"https://twitter.com/search?q=From%3A\" + fish + \"%20since%3A\"+ dt_since +\"%20until%3A\"+ dt_until + \"&src=typed_query&f=live\"\n",
    "            driver = webdriver.Chrome(options=options, executable_path=chrome_path)\n",
    "            driver.get(url)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            dummy = final.shape[0]\n",
    "\n",
    "        if last_height == new_height:\n",
    "            time.sleep(5)\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            if last_height == new_height:\n",
    "                with open(source_path, \"w\") as f:\n",
    "                    f.write(driver.page_source)\n",
    "                    \n",
    "                df = prs_twtr(source_path)\n",
    "                final = final.append(df)\n",
    "                final = final.drop_duplicates(subset='tweet', keep=\"first\")\n",
    "                final.to_csv(base_path + str(fish) + '.csv')\n",
    "                driver.close()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3454, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv(base_path + 'CoinMarketCap.csv')\n",
    "t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
